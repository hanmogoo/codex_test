#!/usr/bin/env python3
"""
ğŸš€ ì™„ì „íˆ ìˆ˜ì •ëœ ex-GPT ê³ ì„±ëŠ¥ ëª¨ë‹ˆí„°
- ì˜¬ë°”ë¥¸ API ìŠ¤í‚¤ë§ˆ ì ìš© âœ…
- 89 QPS + 100% ì„±ê³µë¥  ëª©í‘œ
- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
"""

import asyncio
import aiohttp
import pandas as pd
import json
import time
import threading
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import logging
from collections import deque

class CompleteFixedGPUMonitor:
    """ì™„ì „íˆ ìˆ˜ì •ëœ GPU ìµœì í™” ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.config = {
            # âœ… ìˆ˜ì •ëœ API URL
            'API_URL': 'http://1.215.235.250:28080/v1/chat',
            'TARGET_QPS': 35,
            'MAX_QUERIES': 20,
            'TARGET_TIME': 60,
            
            # ğŸ”¥ ìµœì í™”ëœ ë™ì‹œì„±
            'INITIAL_CONCURRENT': 10,
            'MAX_CONCURRENT': 50,
            'MIN_CONCURRENT': 5,
            
            # âš¡ íƒ€ì´ë° ìµœì í™”
            # ì´ˆê¸°ì—ëŠ” ë°±ì—”ë“œ ì•ˆì •ì„±ì„ ìœ„í•´ 0.4ì´ˆ ì§€ì—°ì„ ë‘ì—ˆìœ¼ë‚˜
            # í˜„ì¬ëŠ” ë¶ˆí•„ìš”í•˜ì—¬ 0ì´ˆë¡œ ì„¤ì •
            'INITIAL_DELAY': 0,
            'TIMEOUT': 10.0,
            'CONNECT_TIMEOUT': 3.0,
            'READ_TIMEOUT': 7.0,
            'MAX_RETRIES': 3,
            
            # ğŸŒ ë„¤íŠ¸ì›Œí¬ ìµœì í™”
            'MAX_CONNECTIONS': 200,
            'MAX_CONNECTIONS_PER_HOST': 100,
            'KEEPALIVE_TIMEOUT': 30,
            
            # ğŸ“ íŒŒì¼ ì„¤ì •
            'EXCEL_FILE': './queries.xlsx',
            'EXCEL_SHEET': 'sheet1',
            'QUERY_COLUMN': 1,
            
            # ğŸ”„ ë™ì  ì¡°ì •
            'AUTO_SCALING': True,
            'SUCCESS_RATE_THRESHOLD': 80,
            'QPS_THRESHOLD': 30,
        }
        
        # ğŸ“Š ì„±ëŠ¥ ë°ì´í„°
        self.completed_requests = deque(maxlen=10000)
        self.start_time = time.time()
        self.current_concurrent = self.config['INITIAL_CONCURRENT']
        self.last_adjustment = time.time()
        self.semaphore = None
        self.active_requests = {}
        
        # ğŸ“ ë¡œê·¸ ì„¤ì •
        self.setup_logging()
        self.monitoring_active = False
        
        # ğŸ¯ ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'current_qps': 0,
            'peak_qps': 0,
            'average_response_time': 0,
            'success_rate': 0,
            'elapsed_time': 0
        }

    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        today = datetime.now().strftime('%Y-%m-%d_%H-%M')
        self.log_dir = Path(f'./fixed-gpu-monitor-{today}')
        self.log_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s | %(message)s',
            handlers=[
                logging.FileHandler(self.log_dir / 'performance.log', encoding='utf-8'),
            ]
        )
        self.logger = logging.getLogger(__name__)

    def create_correct_api_request(self, query: str, index: int) -> Dict[str, Any]:
        """âœ… ì˜¬ë°”ë¥¸ API ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ìš”ì²­ ìƒì„±"""
        return {
                  "message_id": f"msg_{index}",
                  "session_id": f"session_{index}",
                  "user_id": f"user_{index % 50}",
                  "department": "ì„±ëŠ¥í…ŒìŠ¤íŠ¸ë¶€ì„œ",
                  "authorization": "Bearer perf_token",
                  "stream": False,
                  "search_documents": False,
                  "search_scope": ["test_scope"],
                  "history": [
                      {
                          "role": "user",
                          "content": query
                      }
                  ],
                  "search_config": {
                      "max_documents": 20,
                      "min_relevance_score": 0.4,
                      "document_types": ["test"],
                      "date_range": {
                          "additionalProp1": "2020-01-01",
                          "additionalProp2": "2025-12-31",
                          "additionalProp3": ""
                      },
                      "priority_sources": ["test_source"],
                      "do_rerank": True
                  },
                  "response_format": {
                      "type": "markdown",
                      "max_length": 2000,
                      "include_citations": True,
                      "language": "ko",
                      "tone": "formal",
                      "instruction": "",
                      "encode_download_url_key": False
                  },
                  "max_context_tokens": 10000,
                  "temperature": 0.3,
                  "suggest_questions": False,
                  "generate_search_query": True
              }

    def calculate_performance_metrics(self):
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        current_time = time.time()
        elapsed = current_time - self.start_time
        
        if elapsed <= 0:
            return
        
        total = len(self.completed_requests)
        success = sum(1 for r in self.completed_requests if r.get('success', False))
        
        # ìµœê·¼ 10ì´ˆ ê¸°ì¤€ QPS
        recent_requests = [r for r in self.completed_requests 
                          if current_time - r.get('completion_time', 0) <= 10]
        current_qps = len(recent_requests) / min(10, elapsed)
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„
        if success > 0:
            avg_response = sum(r.get('response_time', 0) for r in self.completed_requests 
                             if r.get('success', False)) / success
        else:
            avg_response = 0
        
        self.stats.update({
            'total_requests': total,
            'successful_requests': success,
            'failed_requests': total - success,
            'current_qps': current_qps,
            'peak_qps': max(self.stats['peak_qps'], current_qps),
            'average_response_time': avg_response,
            'success_rate': (success / total * 100) if total > 0 else 0,
            'elapsed_time': elapsed
        })

    def adjust_concurrency(self):
        """ë™ì  ë™ì‹œì„± ì¡°ì •"""
        if not self.config['AUTO_SCALING']:
            return
        
        current_time = time.time()
        if current_time - self.last_adjustment < 5:  # 5ì´ˆë§ˆë‹¤ ì¡°ì •
            return
        
        success_rate = self.stats.get('success_rate', 0)
        current_qps = self.stats.get('current_qps', 0)
        
        old_concurrent = self.current_concurrent
        
        if success_rate > 95 and current_qps < self.config['TARGET_QPS']:
            # ë†’ì€ ì„±ê³µë¥  + ë‚®ì€ QPS â†’ ë™ì‹œì„± ì¦ê°€
            self.current_concurrent = min(
                self.current_concurrent + 10,
                self.config['MAX_CONCURRENT']
            )
        elif success_rate < self.config['SUCCESS_RATE_THRESHOLD']:
            # ë‚®ì€ ì„±ê³µë¥  â†’ ë™ì‹œì„± ê°ì†Œ
            self.current_concurrent = max(
                self.current_concurrent - 5,
                self.config['MIN_CONCURRENT']
            )
        
        if old_concurrent != self.current_concurrent:
            self.logger.info(f"ğŸ”„ ë™ì‹œì„± ì¡°ì •: {old_concurrent} â†’ {self.current_concurrent}")
            self.logger.info(f"ğŸ“Š ì„±ê³µë¥ : {success_rate:.1f}%, QPS: {current_qps:.1f}")
            if self.semaphore is not None:
                # ì„¸ë§ˆí¬ì–´ ìš©ëŸ‰ì„ ìµœì‹  ë™ì‹œì„±ì— ë§ì¶° ì¬ìƒì„±
                self.semaphore = asyncio.Semaphore(self.current_concurrent)
        
        self.last_adjustment = current_time

    def print_realtime_status(self):
        """ì‹¤ì‹œê°„ ìƒíƒœ ì¶œë ¥"""
        self.calculate_performance_metrics()
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ ì™„ì „ ìˆ˜ì •ëœ GPU ëª¨ë‹ˆí„°ë§ [{datetime.now().strftime('%H:%M:%S')}]")
        print(f"{'='*80}")
        
        progress = (len(self.completed_requests) / self.config['MAX_QUERIES']) * 100
        eta = (self.config['MAX_QUERIES'] - len(self.completed_requests)) / max(self.stats['current_qps'], 1)
        
        print(f"ğŸ¯ ëª©í‘œ ì§„í–‰ë¥ : {progress:.1f}% ({len(self.completed_requests)}/{self.config['MAX_QUERIES']})")
        print(f"â±ï¸ ëª©í‘œ ì‹œê°„: {self.config['TARGET_TIME']}ì´ˆ | ê²½ê³¼: {self.stats['elapsed_time']:.1f}ì´ˆ")
        print(f"ğŸ”® ì™„ë£Œ ì˜ˆìƒ: {eta:.1f}ì´ˆ í›„")
        
        print(f"\nğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥:")
        print(f"   ğŸš€ í˜„ì¬ QPS: {self.stats['current_qps']:.1f} (ëª©í‘œ: {self.config['TARGET_QPS']})")
        print(f"   ğŸ† ìµœê³  QPS: {self.stats['peak_qps']:.1f}")
        print(f"   âœ… ì„±ê³µë¥ : {self.stats['success_rate']:.1f}%")
        print(f"   âš¡ í‰ê·  ì‘ë‹µ: {self.stats['average_response_time']:.2f}ì´ˆ")
        print(f"   ğŸ”„ ë™ì‹œ ì²˜ë¦¬: {self.current_concurrent}ê°œ (í™œì„±: {len(self.active_requests)})")
        
        # ğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        if self.stats['current_qps'] >= self.config['TARGET_QPS']:
            print(f"   ğŸ‰ ëª©í‘œ QPS ë‹¬ì„±!")
        if self.stats['success_rate'] >= 90:
            print(f"   ğŸ‰ ë†’ì€ ì„±ê³µë¥  ë‹¬ì„±!")
        
        # ğŸš¨ ê²½ê³  ìƒí™©
        if self.stats['success_rate'] < 80:
            print(f"   ğŸš¨ ë‚®ì€ ì„±ê³µë¥  ê²½ê³ !")
        if eta > self.config['TARGET_TIME']:
            print(f"   âš ï¸ ëª©í‘œ ì‹œê°„ ì´ˆê³¼ ì˜ˆìƒ!")

    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        
        def monitor_loop():
            while self.monitoring_active:
                self.print_realtime_status()
                self.adjust_concurrency()
                time.sleep(2)
        
        monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        monitor_thread.start()

    async def send_request(self, session: aiohttp.ClientSession,
                          query: str, index: int) -> Dict[str, Any]:
        """ê°œë³„ ìš”ì²­ ì „ì†¡"""

        req_id = f"{index:04d}"
        start_time = time.time()

        self.active_requests[req_id] = {
            'query': query,
            'start_time': start_time,
            'index': index
        }
        last_error = None
        for attempt in range(1, self.config.get('MAX_RETRIES', 1) + 1):
            try:
                request_body = self.create_correct_api_request(query, index)

                async with session.post(
                    self.config['API_URL'],
                    json=request_body,
                    timeout=aiohttp.ClientTimeout(
                        total=self.config['TIMEOUT'],
                        connect=self.config['CONNECT_TIMEOUT'],
                        sock_read=self.config['READ_TIMEOUT']
                    )
                ) as response:
                    response_time = time.time() - start_time
                    completion_time = time.time()

                    if response.status == 200:
                        try:
                            response_data = await response.json()
                            print(f"âœ… ì„±ê³µ [{index}]: {response_data}")
                            result = {
                                'index': index,
                                'query': query,
                                'success': True,
                                'response_time': response_time,
                                'completion_time': completion_time,
                                'status': response.status
                            }
                        except Exception as e:
                            print(f"ğŸ’¥ JSON íŒŒì‹± ì‹¤íŒ¨ [{index}] : {e}")
                            result = {
                                'index': index,
                                'query': query,
                                'success': False,
                                'response_time': response_time,
                                'completion_time': completion_time,
                                'error': f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}"
                            }
                    else:
                        error_text = await response.text()
                        print(f"ğŸ’¥ ì‹¤íŒ¨ [{index}] - HTTP {response.status} - ì‘ë‹µ: {error_text[:200]}")
                        result = {
                            'index': index,
                            'query': query,
                            'success': False,
                            'response_time': response_time,
                            'completion_time': completion_time,
                            'error': f"HTTP {response.status} - {error_text[:100]}"
                        }

                    if req_id in self.active_requests:
                        del self.active_requests[req_id]
                    self.completed_requests.append(result)

                    return result

            except (asyncio.TimeoutError, aiohttp.ClientError) as e:
                last_error = e
                if attempt < self.config.get('MAX_RETRIES', 1):
                    print(f"â³ íƒ€ì„ì•„ì›ƒ [{index}] ì¬ì‹œë„ {attempt}/{self.config['MAX_RETRIES']}")
                    await asyncio.sleep(1)
                    continue
            except Exception as e:
                last_error = e
                break

        if req_id in self.active_requests:
            del self.active_requests[req_id]

        result = {
            'index': index,
            'query': query,
            'success': False,
            'response_time': time.time() - start_time,
            'completion_time': time.time(),
            'error': str(last_error) if last_error else 'unknown'
        }
        self.completed_requests.append(result)
        return result
    
    async def run_fixed_test(self, queries: List[str]):
        """ìˆ˜ì •ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        print(f"ğŸš€ ì™„ì „ ìˆ˜ì •ëœ GPU ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘!")
        print(f"ğŸ¯ ëª©í‘œ: {len(queries)}ê°œ ì§ˆì˜ë¥¼ {self.config['TARGET_TIME']}ì´ˆ ì•ˆì— ì²˜ë¦¬")
        print(f"ğŸ“Š ëª©í‘œ QPS: {self.config['TARGET_QPS']:.1f}")
        print(f"ğŸ”§ ì˜¬ë°”ë¥¸ API ìŠ¤í‚¤ë§ˆ ì ìš©")
        print(f"âš¡ ìë™ ìŠ¤ì¼€ì¼ë§: {'âœ…' if self.config['AUTO_SCALING'] else 'âŒ'}")
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.start_monitoring()
        
        # ìµœì í™”ëœ ì»¤ë„¥í„° ì„¤ì •
        connector = aiohttp.TCPConnector(
            limit=self.config['MAX_CONNECTIONS'],
            limit_per_host=self.config['MAX_CONNECTIONS_PER_HOST'],
            keepalive_timeout=self.config['KEEPALIVE_TIMEOUT'],
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(
            total=self.config['TIMEOUT'],
            connect=self.config['CONNECT_TIMEOUT']
        )
        
        async with aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'FixedGPUMonitor/1.0'}
        ) as session:
            
            # ë™ì  ì„¸ë§ˆí¬ì–´
            self.semaphore = asyncio.Semaphore(self.current_concurrent)


            async def process_query_with_semaphore(query: str, index: int):
              async with self.semaphore:
                  await asyncio.sleep(self.config['INITIAL_DELAY'])
                  return await self.send_request(session, query, index)
            
            print(f"ğŸ”„ 3ì´ˆ í›„ ì‹œì‘...")
            await asyncio.sleep(3)
            
            # ëª¨ë“  ìš”ì²­ ë™ì‹œ ì‹¤í–‰
            tasks = [process_query_with_semaphore(query, i+1) 
                    for i, query in enumerate(queries)]
            
            # ì§„í–‰ë¥  ì¶”ì 
            for i, task in enumerate(asyncio.as_completed(tasks)):
                await task
                if (i + 1) % 100 == 0:  # 100ê°œë§ˆë‹¤ ë¡œê·¸
                    elapsed = time.time() - self.start_time
                    current_qps = len(self.completed_requests) / elapsed if elapsed > 0 else 0
                    self.logger.info(f"ì§„í–‰: {i+1}/{len(tasks)}, QPS: {current_qps:.1f}")
        
        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
        self.monitoring_active = False
        
        # ìµœì¢… ê²°ê³¼
        self.print_final_results()

    def print_final_results(self):
        """ìµœì¢… ê²°ê³¼ ë¶„ì„"""
        self.calculate_performance_metrics()
        
        print(f"\n{'='*80}")
        print(f"ğŸ¯ ì™„ì „ ìˆ˜ì •ëœ í…ŒìŠ¤íŠ¸ ìµœì¢… ê²°ê³¼")
        print(f"{'='*80}")
        
        total_time = self.stats['elapsed_time']
        achieved_qps = self.stats['total_requests'] / total_time if total_time > 0 else 0
        
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   ì´ ì²˜ë¦¬: {self.stats['total_requests']}ê°œ")
        print(f"   ì„±ê³µ: {self.stats['successful_requests']}ê°œ")
        print(f"   ì‹¤íŒ¨: {self.stats['failed_requests']}ê°œ")
        print(f"   ì„±ê³µë¥ : {self.stats['success_rate']:.1f}%")
        
        print(f"\nâš¡ ì„±ëŠ¥ ê²°ê³¼:")
        print(f"   ì‹¤ì œ QPS: {achieved_qps:.1f} (ëª©í‘œ: {self.config['TARGET_QPS']})")
        print(f"   ìµœê³  QPS: {self.stats['peak_qps']:.1f}")
        print(f"   ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ (ëª©í‘œ: {self.config['TARGET_TIME']}ì´ˆ)")
        print(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {self.stats['average_response_time']:.2f}ì´ˆ")
        
        # ğŸ¯ ëª©í‘œ ë‹¬ì„± í‰ê°€
        qps_achieved = achieved_qps >= self.config['TARGET_QPS']
        time_achieved = total_time <= self.config['TARGET_TIME']
        success_rate_good = self.stats['success_rate'] >= 90
        
        print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± í‰ê°€:")
        print(f"   QPS ëª©í‘œ: {'âœ… ë‹¬ì„±' if qps_achieved else 'âŒ ë¯¸ë‹¬'}")
        print(f"   ì‹œê°„ ëª©í‘œ: {'âœ… ë‹¬ì„±' if time_achieved else 'âŒ ì´ˆê³¼'}")
        print(f"   ì„±ê³µë¥ : {'âœ… ìš°ìˆ˜' if success_rate_good else 'âš ï¸ ê°œì„ í•„ìš”'}")
        
        overall_success = qps_achieved and time_achieved and success_rate_good
        print(f"   ğŸ† ì¢…í•© í‰ê°€: {'ğŸ‰ ì™„ì „ ì„±ê³µ!' if overall_success else 'ğŸ“ˆ ê°œì„  í•„ìš”'}")
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        report = {
            'config': self.config,
            'final_stats': self.stats,
            'completed_requests': list(self.completed_requests),
            'timestamp': datetime.now().isoformat()
        }
        
        report_file = self.log_dir / 'fixed_performance_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì„±ëŠ¥ ë³´ê³ ì„œ: {report_file}")

    def load_queries(self) -> List[str]:
        """ì§ˆì˜ ë¡œë“œ"""
        try:
            df = pd.read_excel(self.config['EXCEL_FILE'], sheet_name=self.config['EXCEL_SHEET'])
            queries = df.iloc[:, self.config['QUERY_COLUMN']].dropna().astype(str).tolist()
            queries = [q.strip() for q in queries if len(q.strip()) > 3]
            return queries[:self.config['MAX_QUERIES']]
        except Exception as e:
            print(f"âš ï¸ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì§ˆì˜ ìƒì„±
            return [f"í…ŒìŠ¤íŠ¸ ì§ˆì˜ {i+1}: ë„ë¡œ ê´€ë ¨ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”." for i in range(100)]

async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print('ğŸš€ ì™„ì „ ìˆ˜ì •ëœ ex-GPT GPU ìµœì í™” ëª¨ë‹ˆí„°ë§')
    print('ğŸ¯ ëª©í‘œ: 89 QPS + 100% ì„±ê³µë¥ ')
    print('âœ… ì˜¬ë°”ë¥¸ API ìŠ¤í‚¤ë§ˆ ì ìš©')
    print(f'ì‹œì‘: {datetime.now().strftime("%Y.%m.%d %H:%M:%S")}')
    
    monitor = CompleteFixedGPUMonitor()
    
    queries = monitor.load_queries()
    print(f"âœ… {len(queries)}ê°œ ì§ˆì˜ ë¡œë“œ ì™„ë£Œ")
    
    if len(queries) < monitor.config['MAX_QUERIES']:
        print(f"âš ï¸ ìš”ì²­í•œ {monitor.config['MAX_QUERIES']}ê°œë³´ë‹¤ ì ì€ {len(queries)}ê°œë§Œ ë¡œë“œë¨")
        monitor.config['MAX_QUERIES'] = len(queries)
        monitor.config['TARGET_QPS'] = len(queries) / monitor.config['TARGET_TIME']
        print(f"ğŸ”„ ëª©í‘œ QPS ìë™ ì¡°ì •: {monitor.config['TARGET_QPS']:.1f}")
    
    await monitor.run_fixed_test(queries)
    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)